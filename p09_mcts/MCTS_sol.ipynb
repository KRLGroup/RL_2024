{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43849ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebb29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "\n",
    "class TicTacToe:\n",
    "    \"\"\"TicTacToe Board.\"\"\"\n",
    "    \n",
    "    EMPTY = ' '\n",
    "    P1 = 'X'\n",
    "    P2 = 'O'\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a TicTacToe board.\"\"\"\n",
    "        \n",
    "        self.initial_state = []\n",
    "        for i in range(3):\n",
    "            self.initial_state.append([' ']*3)\n",
    "            \n",
    "        self.players = (self.P1, self.P2)\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    @classmethod\n",
    "    def switch_player(cls, player):\n",
    "        \"\"\"Class method that, given a player, returns its opponent\"\"\"\n",
    "        \n",
    "        return cls.P2 if player == cls.P1 else cls.P1\n",
    "        \n",
    "\n",
    "    @classmethod\n",
    "    def check_termination(cls, state):\n",
    "        \"\"\"\n",
    "        Termination check.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        done: bool\n",
    "            A boolean indicating the termination\n",
    "            \n",
    "        winning_player: str\n",
    "            The name of the winning player. The empty cell is returned in case of a draw.\n",
    "        \"\"\"\n",
    "\n",
    "        done = False\n",
    "        winning_player = ' '\n",
    "        \n",
    "        for i in range(3):\n",
    "            first_elem = state[i][0]\n",
    "            if first_elem != cls.EMPTY:\n",
    "                done = all(state[i][j]==first_elem for j in range(3))\n",
    "                if done:\n",
    "                    return done, first_elem\n",
    "                \n",
    "            first_elem = state[0][i]\n",
    "            if first_elem != cls.EMPTY:\n",
    "                done = all(state[j][i]==first_elem for j in range(3))\n",
    "                if done:\n",
    "                    return done, first_elem\n",
    "                \n",
    "        first_elem = state[0][0]\n",
    "        if first_elem != cls.EMPTY:\n",
    "            done = all(state[i][i]==first_elem for i in range(3))\n",
    "            if done:\n",
    "                return done, first_elem\n",
    "        \n",
    "        first_elem = state[0][2]\n",
    "        if first_elem != cls.EMPTY:\n",
    "            done = all(state[i][2-i]==first_elem for i in range(3))\n",
    "            if done:\n",
    "                return done, first_elem\n",
    "        \n",
    "        done = all(state[i][j] != cls.EMPTY for i in range(3) for j in range(3))\n",
    "        \n",
    "        return done, winning_player\n",
    "\n",
    "    @classmethod\n",
    "    def get_available_moves(cls, state):\n",
    "        \"\"\"Class method that, given a state, returns the free cells\"\"\"\n",
    "        \n",
    "        return [(i,j) for i in range(3) for j in range(3) if state[i][j] == ' ']\n",
    "        \n",
    "    @property    \n",
    "    def available_moves(self):\n",
    "        \"\"\"Available moves at current state\"\"\"\n",
    "        \n",
    "        return self.get_available_moves(self.current_state)\n",
    "    \n",
    "    @classmethod\n",
    "    def transition_function(cls, state, action, player):\n",
    "        \"\"\"Transition function\"\"\"\n",
    "        \n",
    "        assert state[action[0]][action[1]] == cls.EMPTY\n",
    "        \n",
    "        state[action[0]][action[1]] = player\n",
    "        player = cls.switch_player(player)\n",
    "        return state, player\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"Step function\"\"\"\n",
    "        \n",
    "        self.done, winning_player = self.check_termination(self.current_state)\n",
    "        assert self.done == False\n",
    "        \n",
    "        self.current_state, self.current_player = self.transition_function(self.current_state, action, self.current_player)\n",
    "        \n",
    "        reward = 0\n",
    "        self.done, winning_player = self.check_termination(self.current_state)\n",
    "        if winning_player == self.player:\n",
    "            reward = 1\n",
    "        if winning_player == self.switch_player(self.player):\n",
    "            reward = -1\n",
    "        \n",
    "        return self.current_state, reward, self.done, self.current_player\n",
    "    \n",
    "    def render(self, state=None):\n",
    "        \"\"\"Render function\"\"\"\n",
    "\n",
    "        if state is None:\n",
    "            state = self.current_state\n",
    "        \n",
    "        for i in range(3):\n",
    "            print('-----------')\n",
    "            print(\"|\".join((f\" {x} \" for x in state[i])))\n",
    "        print('-----------')\n",
    "    \n",
    "    def reset(self, player=None):\n",
    "        \"\"\"\n",
    "        Resets the environment.\n",
    "        \n",
    "        Player 'X' always moves first. If 'O' is selected, the first move is made\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        self.done = False\n",
    "        self.player = player\n",
    "        if self.player is None:\n",
    "            self.player = self.P1\n",
    "        \n",
    "        self.current_state = deepcopy(self.initial_state)\n",
    "        self.current_player = self.P1\n",
    "        \n",
    "        if player == self.P2:\n",
    "            self.step(random.choice(self.available_moves))\n",
    "            \n",
    "        return self.current_state, self.current_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc746a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNode:\n",
    "    \"\"\"MCTS Node.\"\"\"\n",
    "    \n",
    "    def __init__(self, state, player, parent=None, action=None):\n",
    "        \"\"\"Initialize a node.\"\"\"\n",
    "        \n",
    "        self.state = state\n",
    "        self.player = player\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = []\n",
    "        self.untried_actions = TicTacToe.get_available_moves(self.state)\n",
    "        self.n = 0\n",
    "        self.w = 0\n",
    "        self.is_terminal = TicTacToe.check_termination(self.state)[0]\n",
    "\n",
    "    @property\n",
    "    def fully_expanded(self):\n",
    "        return len(self.untried_actions) == 0\n",
    "    \n",
    "    def expand(self):\n",
    "        \"\"\"Pick an untried action, evaluate it, generate the node for the resulting state (also add it to the children) and return it.\"\"\"\n",
    "        \n",
    "        action = self.untried_actions.pop()\n",
    "        \n",
    "        next_state, next_player = TicTacToe.transition_function(deepcopy(self.state), action, self.player)\n",
    "        \n",
    "        child_node = MCTSNode(next_state, next_player, parent=self, action=action)\n",
    "        \n",
    "        self.children.append(child_node)\n",
    "        \n",
    "        return child_node\n",
    "    \n",
    "    def rollout(self):\n",
    "        \"\"\"Until termination, move randomly. Return the result (winning player)\"\"\"\n",
    "        \n",
    "        state = self.state\n",
    "        player = self.player\n",
    "        done, result = TicTacToe.check_termination(state)\n",
    "        while not done:\n",
    "            possible_actions = TicTacToe.get_available_moves(state)\n",
    "            action = random.choice(possible_actions)\n",
    "            state, player = TicTacToe.transition_function(deepcopy(state), action, player)\n",
    "            done, result = TicTacToe.check_termination(state)\n",
    "        return result\n",
    "    \n",
    "    def backpropagate(self, result):\n",
    "        \"\"\"Backprop the result of a rollout up to the root node: For each node in the path update the visits and the number of wins\"\"\"\n",
    "        \n",
    "        self.n += 1\n",
    "        if self.parent:\n",
    "            if result == self.parent.player:\n",
    "                self.w += 1\n",
    "            elif result != ' ':\n",
    "                self.w -= 1\n",
    "            self.parent.backpropagate(result)\n",
    "            \n",
    "    def traverse(self):\n",
    "        \"\"\"Traverse the nodes until an unexpanded one is found or termination is reached\"\"\"\n",
    "        \n",
    "        node = self\n",
    "        \n",
    "        while node.fully_expanded and not node.is_terminal:\n",
    "            node = node.best_uct_child()\n",
    "            \n",
    "        if node.is_terminal:\n",
    "            return node\n",
    "        \n",
    "        return node.expand()\n",
    "    \n",
    "    def win_ratio(self):\n",
    "        \"\"\"Win Ratio of a node\"\"\"\n",
    "        \n",
    "        return self.w/self.n\n",
    "    \n",
    "    def uct(self):\n",
    "        \"\"\"UCT value of a node\"\"\"\n",
    "        \n",
    "        return self.win_ratio() + math.sqrt(2*math.log(self.parent.n)/self.n)\n",
    "    \n",
    "    def best_child(self):\n",
    "        \"\"\"Return the best child (the one with the highest win ratio)\"\"\"\n",
    "        \n",
    "        best_win_ratio, child = max((self.children[i].win_ratio(), i) for i in range(len(self.children)))\n",
    "#         import numpy as np\n",
    "#         m = np.zeros((3,3))\n",
    "        \n",
    "#         for c in self.children:\n",
    "#             m[c.action] = c.win_ratio()*c.n\n",
    "            \n",
    "#         for i in range(3):\n",
    "#             print(' '.join([str(round(e,2)) for e in m[i]]))\n",
    "        \n",
    "        return self.children[child]\n",
    "        \n",
    "    def best_uct_child(self):\n",
    "        \"\"\"Return the best child according to UCT\"\"\"\n",
    "\n",
    "        best_win_ratio, child = max((self.children[i].uct(), i) for i in range(len(self.children)))\n",
    "\n",
    "        return self.children[child]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ebc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts(state, player, iters=5000):\n",
    "    root = MCTSNode(deepcopy(state), player)\n",
    "    for i in range(iters):\n",
    "        leaf = root.traverse()\n",
    "        simulation_result = leaf.rollout()\n",
    "        leaf.backpropagate(simulation_result)\n",
    "\n",
    "    return root.best_child().action, root        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e76ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0480c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4f124",
   "metadata": {},
   "source": [
    "# Random Agents (X and O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a1d269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward over 10 episodes: 0.4\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for i in range(10):\n",
    "    state, cur_player = env.reset(player)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action = random.choice(env.available_moves)\n",
    "        state, reward, done, cur_player = env.step(action)\n",
    "        total_reward += reward\n",
    "    rewards.append(total_reward)\n",
    "\n",
    "print('Mean Reward over 10 episodes:', sum(rewards)/len(rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9641a",
   "metadata": {},
   "source": [
    "# MCTS Agent (X) and Random Agend (O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b30071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O | X |   \n",
      "-----------\n",
      "-----------\n",
      "   |   | O \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O | X |   \n",
      "-----------\n",
      "-----------\n",
      "   | X | O \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O | X |   \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "state, cur_player = env.reset(player)\n",
    "done = False\n",
    "\n",
    "env.render()\n",
    "\n",
    "while not done:\n",
    "    if cur_player == player:\n",
    "        action, root = mcts(deepcopy(state), player)\n",
    "    else:\n",
    "        action = random.choice(env.available_moves)\n",
    "    state, reward, done, cur_player = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76af70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward over 10 episodes: 1.0\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for i in range(10):\n",
    "    state, cur_player = env.reset(player)\n",
    "    done = False\n",
    "\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        if cur_player == player:\n",
    "            action, root = mcts(deepcopy(state), player)\n",
    "        else:\n",
    "            action = random.choice(env.available_moves)\n",
    "        state, reward, done, cur_player = env.step(action)\n",
    "        total_reward += reward\n",
    "    rewards.append(total_reward)\n",
    "\n",
    "print('Mean Reward over 10 episodes:', sum(rewards)/len(rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49295f76",
   "metadata": {},
   "source": [
    "# MCTS Agents (X and O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f158cc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   | O \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      "   | X | X \n",
      "-----------\n",
      "   |   | O \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      " O | X | X \n",
      "-----------\n",
      "   |   | O \n",
      "-----------\n",
      "-----------\n",
      "   |   |   \n",
      "-----------\n",
      " O | X | X \n",
      "-----------\n",
      "   | X | O \n",
      "-----------\n",
      "-----------\n",
      "   | O |   \n",
      "-----------\n",
      " O | X | X \n",
      "-----------\n",
      "   | X | O \n",
      "-----------\n",
      "-----------\n",
      "   | O | X \n",
      "-----------\n",
      " O | X | X \n",
      "-----------\n",
      "   | X | O \n",
      "-----------\n",
      "-----------\n",
      "   | O | X \n",
      "-----------\n",
      " O | X | X \n",
      "-----------\n",
      " O | X | O \n",
      "-----------\n",
      "-----------\n",
      " X | O | X \n",
      "-----------\n",
      " O | X | X \n",
      "-----------\n",
      " O | X | O \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "state, cur_player = env.reset(player)\n",
    "done = False\n",
    "\n",
    "env.render()\n",
    "\n",
    "while not done:\n",
    "    action, root = mcts(deepcopy(state), cur_player)\n",
    "    state, reward, done, cur_player = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faab291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward over 10 episodes: 0.0\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for i in range(10):\n",
    "    state, cur_player = env.reset(player)\n",
    "    done = False\n",
    "\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, root = mcts(deepcopy(state), cur_player)\n",
    "        state, reward, done, cur_player = env.step(action)\n",
    "        total_reward += reward\n",
    "    rewards.append(total_reward)\n",
    "\n",
    "print('Mean Reward over 10 episodes:', sum(rewards)/len(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b2cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
